{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMporting the libraries\n",
    "import pyspark\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 3 features:  'Type', 'Age', 'Breed1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pyspark to read the data and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To work with spark we need to create a spark session\n",
    "# Need to instal java\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('petfinder').getOrCreate()\n",
    "\n",
    "########### For the train dataset\n",
    "# Read a dataset with spark\n",
    "df_spark = spark.read.csv('./train_balanced_corr.csv', header=True, inferSchema=True)\n",
    "# Header = True, inferSchema = True, means that the first row is the header and the schema is inferred (if schema is not inferred, all columns will be read as string)\n",
    "# Convert the column \"AdoptionSpeed\" to integer\n",
    "df_spark = df_spark.withColumn(\"AdoptionSpeed\", df_spark[\"AdoptionSpeed\"].cast(\"integer\"))\n",
    "\n",
    "\n",
    "############ For the test dataset\n",
    "# Read a dataset with spark\n",
    "df_spark_test = spark.read.csv('./test_split_corr.csv', header=True, inferSchema=True)\n",
    "# Header = True, inferSchema = True, means that the first row is the header and the schema is inferred (if schema is not inferred, all columns will be read as string)\n",
    "# Convert the column \"AdoptionSpeed\" to integer\n",
    "df_spark_test = df_spark_test.withColumn(\"AdoptionSpeed\", df_spark_test[\"AdoptionSpeed\"].cast(\"integer\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+-------------+\n",
      "|Breed1|Age|Type|AdoptionSpeed|\n",
      "+------+---+----+-------------+\n",
      "|   307|  2|   1|            1|\n",
      "|   307| 36|   1|            4|\n",
      "|   179|  2|   1|            1|\n",
      "|   265| 27|   2|            4|\n",
      "|   307|  2|   1|            1|\n",
      "|   266| 29|   2|            4|\n",
      "|    83| 36|   1|            1|\n",
      "|   307| 24|   1|            3|\n",
      "|   307| 21|   1|            4|\n",
      "|   307| 29|   1|            3|\n",
      "|   307|  3|   1|            2|\n",
      "|    60|120|   1|            2|\n",
      "|   145| 18|   1|            2|\n",
      "|   254| 24|   2|            3|\n",
      "|   205| 36|   1|            2|\n",
      "|   307|  2|   1|            3|\n",
      "|   266| 12|   2|            3|\n",
      "|   307|  3|   1|            2|\n",
      "|   283| 48|   2|            4|\n",
      "|   265|  3|   2|            2|\n",
      "+------+---+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+---+----+-------------+\n",
      "|Breed1|Age|Type|AdoptionSpeed|\n",
      "+------+---+----+-------------+\n",
      "|   265|  7|   2|            4|\n",
      "|   266| 24|   2|            4|\n",
      "|   266| 12|   2|            2|\n",
      "|   195| 60|   1|            1|\n",
      "|   266|  3|   2|            4|\n",
      "|   307| 12|   1|            2|\n",
      "|   218| 16|   1|            4|\n",
      "|   285| 24|   2|            3|\n",
      "|   266| 36|   2|            4|\n",
      "|   108|  8|   1|            2|\n",
      "|   307| 36|   1|            3|\n",
      "|   307| 15|   1|            4|\n",
      "|    20| 60|   1|            2|\n",
      "|   307| 18|   1|            3|\n",
      "|   307|  1|   1|            1|\n",
      "|   252| 60|   2|            3|\n",
      "|   285|  6|   2|            2|\n",
      "|    88|  2|   1|            3|\n",
      "|   307|  3|   1|            1|\n",
      "|   307|  1|   1|            1|\n",
      "+------+---+----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########### For the train dataset\n",
    "\n",
    "## Drop rows with missing values\n",
    "# df_spark.na.drop(how='all', thresh=10).show() \n",
    "    ### how='any' means drop rows with any missing value, how='all' means drop rows whose all values are missing\n",
    "    ### thresh=10 means drop rows whose number of missing values is greater than 10\n",
    "    ### subset=['Age'] means drop rows whose 'Age' value is missing\n",
    "df_spark = df_spark.na.drop(how= 'any' , subset=['AdoptionSpeed'])\n",
    "## Fill missing values with mean\n",
    "from pyspark.sql.functions import mean\n",
    "mean_val = df_spark.select(mean(df_spark['Age'])).collect()\n",
    "mean_age = mean_val[0][0]\n",
    "df_spark.na.fill(mean_age, subset=['Age']).show()\n",
    "\n",
    "########### For the test dataset\n",
    "\n",
    "df_spark_test = df_spark_test.na.drop(how= 'any' , subset=['AdoptionSpeed'])\n",
    "## Fill missing values with mean\n",
    "from pyspark.sql.functions import mean\n",
    "mean_val = df_spark_test.select(mean(df_spark_test['Age'])).collect()\n",
    "mean_age = mean_val[0][0]\n",
    "df_spark_test.na.fill(mean_age, subset=['Age']).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PySpark MLlib to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+-------------+----------------+\n",
      "|Breed1|Age|Type|AdoptionSpeed|        features|\n",
      "+------+---+----+-------------+----------------+\n",
      "|   307|  2|   1|            1| [307.0,2.0,1.0]|\n",
      "|   307| 36|   1|            4|[307.0,36.0,1.0]|\n",
      "|   179|  2|   1|            1| [179.0,2.0,1.0]|\n",
      "|   265| 27|   2|            4|[265.0,27.0,2.0]|\n",
      "|   307|  2|   1|            1| [307.0,2.0,1.0]|\n",
      "|   266| 29|   2|            4|[266.0,29.0,2.0]|\n",
      "|    83| 36|   1|            1| [83.0,36.0,1.0]|\n",
      "|   307| 24|   1|            3|[307.0,24.0,1.0]|\n",
      "|   307| 21|   1|            4|[307.0,21.0,1.0]|\n",
      "|   307| 29|   1|            3|[307.0,29.0,1.0]|\n",
      "|   307|  3|   1|            2| [307.0,3.0,1.0]|\n",
      "|    60|120|   1|            2|[60.0,120.0,1.0]|\n",
      "|   145| 18|   1|            2|[145.0,18.0,1.0]|\n",
      "|   254| 24|   2|            3|[254.0,24.0,2.0]|\n",
      "|   205| 36|   1|            2|[205.0,36.0,1.0]|\n",
      "|   307|  2|   1|            3| [307.0,2.0,1.0]|\n",
      "|   266| 12|   2|            3|[266.0,12.0,2.0]|\n",
      "|   307|  3|   1|            2| [307.0,3.0,1.0]|\n",
      "|   283| 48|   2|            4|[283.0,48.0,2.0]|\n",
      "|   265|  3|   2|            2| [265.0,3.0,2.0]|\n",
      "+------+---+----+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+---+----+-------------+----------------+\n",
      "|Breed1|Age|Type|AdoptionSpeed|        features|\n",
      "+------+---+----+-------------+----------------+\n",
      "|   265|  7|   2|            4| [265.0,7.0,2.0]|\n",
      "|   266| 24|   2|            4|[266.0,24.0,2.0]|\n",
      "|   266| 12|   2|            2|[266.0,12.0,2.0]|\n",
      "|   195| 60|   1|            1|[195.0,60.0,1.0]|\n",
      "|   266|  3|   2|            4| [266.0,3.0,2.0]|\n",
      "|   307| 12|   1|            2|[307.0,12.0,1.0]|\n",
      "|   218| 16|   1|            4|[218.0,16.0,1.0]|\n",
      "|   285| 24|   2|            3|[285.0,24.0,2.0]|\n",
      "|   266| 36|   2|            4|[266.0,36.0,2.0]|\n",
      "|   108|  8|   1|            2| [108.0,8.0,1.0]|\n",
      "|   307| 36|   1|            3|[307.0,36.0,1.0]|\n",
      "|   307| 15|   1|            4|[307.0,15.0,1.0]|\n",
      "|    20| 60|   1|            2| [20.0,60.0,1.0]|\n",
      "|   307| 18|   1|            3|[307.0,18.0,1.0]|\n",
      "|   307|  1|   1|            1| [307.0,1.0,1.0]|\n",
      "|   252| 60|   2|            3|[252.0,60.0,2.0]|\n",
      "|   285|  6|   2|            2| [285.0,6.0,2.0]|\n",
      "|    88|  2|   1|            3|  [88.0,2.0,1.0]|\n",
      "|   307|  3|   1|            1| [307.0,3.0,1.0]|\n",
      "|   307|  1|   1|            1| [307.0,1.0,1.0]|\n",
      "+------+---+----+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, collect the features in a single column\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#### For the train dataset\n",
    "featureassemble = VectorAssembler(inputCols=['Breed1','Age','Type'], outputCol='features')\n",
    "output = featureassemble.transform(df_spark) # This will create a new column called 'features' which is a vector of the selected columns (Type, Age2, Breed1) by the VectorAssembler\n",
    "output.show()\n",
    "\n",
    "#### For the test dataset\n",
    "testfeatureassemble = VectorAssembler(inputCols=['Breed1','Age','Type'], outputCol='features')\n",
    "testoutput = testfeatureassemble.transform(df_spark_test) # This will create a new column called 'features' which is a vector of the selected columns (Type, Age2, Breed1) by the VectorAssembler\n",
    "testoutput.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|        features|AdoptionSpeed|\n",
      "+----------------+-------------+\n",
      "| [307.0,2.0,1.0]|            1|\n",
      "|[307.0,36.0,1.0]|            4|\n",
      "| [179.0,2.0,1.0]|            1|\n",
      "|[265.0,27.0,2.0]|            4|\n",
      "| [307.0,2.0,1.0]|            1|\n",
      "|[266.0,29.0,2.0]|            4|\n",
      "| [83.0,36.0,1.0]|            1|\n",
      "|[307.0,24.0,1.0]|            3|\n",
      "|[307.0,21.0,1.0]|            4|\n",
      "|[307.0,29.0,1.0]|            3|\n",
      "| [307.0,3.0,1.0]|            2|\n",
      "|[60.0,120.0,1.0]|            2|\n",
      "|[145.0,18.0,1.0]|            2|\n",
      "|[254.0,24.0,2.0]|            3|\n",
      "|[205.0,36.0,1.0]|            2|\n",
      "| [307.0,2.0,1.0]|            3|\n",
      "|[266.0,12.0,2.0]|            3|\n",
      "| [307.0,3.0,1.0]|            2|\n",
      "|[283.0,48.0,2.0]|            4|\n",
      "| [265.0,3.0,2.0]|            2|\n",
      "+----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------------+-------------+\n",
      "|        features|AdoptionSpeed|\n",
      "+----------------+-------------+\n",
      "| [265.0,7.0,2.0]|            4|\n",
      "|[266.0,24.0,2.0]|            4|\n",
      "|[266.0,12.0,2.0]|            2|\n",
      "|[195.0,60.0,1.0]|            1|\n",
      "| [266.0,3.0,2.0]|            4|\n",
      "|[307.0,12.0,1.0]|            2|\n",
      "|[218.0,16.0,1.0]|            4|\n",
      "|[285.0,24.0,2.0]|            3|\n",
      "|[266.0,36.0,2.0]|            4|\n",
      "| [108.0,8.0,1.0]|            2|\n",
      "|[307.0,36.0,1.0]|            3|\n",
      "|[307.0,15.0,1.0]|            4|\n",
      "| [20.0,60.0,1.0]|            2|\n",
      "|[307.0,18.0,1.0]|            3|\n",
      "| [307.0,1.0,1.0]|            1|\n",
      "|[252.0,60.0,2.0]|            3|\n",
      "| [285.0,6.0,2.0]|            2|\n",
      "|  [88.0,2.0,1.0]|            3|\n",
      "| [307.0,3.0,1.0]|            1|\n",
      "| [307.0,1.0,1.0]|            1|\n",
      "+----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the features and the target column\n",
    "\n",
    "#### For the train dataset\n",
    "finalized_data = output.select('features', 'AdoptionSpeed') # Select the features and the target column\n",
    "finalized_data.show()\n",
    "\n",
    "#### For the test dataset\n",
    "testfinalized_data = testoutput.select('features', 'AdoptionSpeed') # Select the features and the target column\n",
    "testfinalized_data.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "|        features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "| [265.0,7.0,2.0]|            4|[0.21852222769436...|[0.24594501729175...|       0.0|\n",
      "|[266.0,24.0,2.0]|            4|[0.21091546173330...|[0.24452052550620...|       0.0|\n",
      "|[266.0,12.0,2.0]|            2|[0.21328101316232...|[0.24531022067589...|       0.0|\n",
      "|[195.0,60.0,1.0]|            1|[0.02040640887454...|[0.19880089651182...|       4.0|\n",
      "| [266.0,3.0,2.0]|            4|[0.21505517673408...|[0.24453461523033...|       0.0|\n",
      "|[307.0,12.0,1.0]|            2|[-0.4467550129775...|[0.12267623478828...|       4.0|\n",
      "|[218.0,16.0,1.0]|            4|[-0.0687979689279...|[0.18565850870324...|       3.0|\n",
      "|[285.0,24.0,2.0]|            3|[0.13005966777085...|[0.22530280619895...|       4.0|\n",
      "|[266.0,36.0,2.0]|            4|[0.20854991030428...|[0.24150748150536...|       4.0|\n",
      "| [108.0,8.0,1.0]|            2|[0.40089155671957...|[0.27045693183075...|       0.0|\n",
      "|[307.0,36.0,1.0]|            3|[-0.4514861158355...|[0.11561227728769...|       4.0|\n",
      "|[307.0,15.0,1.0]|            4|[-0.4473464008347...|[0.12205561826722...|       4.0|\n",
      "| [20.0,60.0,1.0]|            2|[0.76513082694975...|[0.37992074510452...|       0.0|\n",
      "|[307.0,18.0,1.0]|            3|[-0.4479377886920...|[0.12135902382152...|       4.0|\n",
      "| [307.0,1.0,1.0]|            1|[-0.4445865908342...|[0.12430448146949...|       3.0|\n",
      "|[252.0,60.0,2.0]|            3|[0.26339676089227...|[0.24536736172959...|       4.0|\n",
      "| [285.0,6.0,2.0]|            2|[0.13360799491437...|[0.22748000118850...|       0.0|\n",
      "|  [88.0,2.0,1.0]|            3|[0.48718569449982...|[0.28215701802101...|       1.0|\n",
      "| [307.0,3.0,1.0]|            1|[-0.4449808494057...|[0.12408352119394...|       4.0|\n",
      "| [307.0,1.0,1.0]|            1|[-0.4445865908342...|[0.12430448146949...|       3.0|\n",
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            4|       0.0|\n",
      "|            4|       0.0|\n",
      "|            2|       0.0|\n",
      "|            1|       4.0|\n",
      "|            4|       0.0|\n",
      "|            2|       4.0|\n",
      "|            4|       3.0|\n",
      "|            3|       4.0|\n",
      "|            4|       4.0|\n",
      "|            2|       0.0|\n",
      "|            3|       4.0|\n",
      "|            4|       4.0|\n",
      "|            2|       0.0|\n",
      "|            3|       4.0|\n",
      "|            1|       3.0|\n",
      "|            3|       4.0|\n",
      "|            2|       0.0|\n",
      "|            3|       1.0|\n",
      "|            1|       4.0|\n",
      "|            1|       3.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "F1 score: 0.193\n",
      "+------------------------+---+---+---+---+\n",
      "|AdoptionSpeed_prediction|0.0|1.0|3.0|4.0|\n",
      "+------------------------+---+---+---+---+\n",
      "|                       3|281| 30|166|165|\n",
      "|                       0| 47|  8| 16| 10|\n",
      "|                       1|364| 40|163| 52|\n",
      "|                       4|323| 16|154|330|\n",
      "|                       2|408| 36|236|154|\n",
      "+------------------------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Split the data into training and validation data\n",
    "train_data = finalized_data\n",
    "classifier = LogisticRegression\n",
    "classifier = LogisticRegression(labelCol='AdoptionSpeed').fit(train_data) # Fit the model\n",
    "\n",
    "\n",
    "test_data = testfinalized_data\n",
    "results = classifier.evaluate(test_data) # Evaluate the model on the validation data\n",
    "results.predictions.show() # Show the predictions\n",
    "results.predictions.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "\n",
    "# Want to show the f1 score and confusion matrix\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AdoptionSpeed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(results.predictions)\n",
    "print(\"F1 score: %.3f\" % f1_score)\n",
    "\n",
    "# Confusion matrix\n",
    "results.predictions.crosstab('AdoptionSpeed', 'prediction').show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "|        features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "| [265.0,7.0,2.0]|            4|[388.0,258.0,317....|[0.19715447154471...|       4.0|\n",
      "|[266.0,24.0,2.0]|            4|[388.0,258.0,317....|[0.19715447154471...|       4.0|\n",
      "|[266.0,12.0,2.0]|            2|[388.0,258.0,317....|[0.19715447154471...|       4.0|\n",
      "|[195.0,60.0,1.0]|            1|[380.0,195.0,147....|[0.39915966386554...|       0.0|\n",
      "| [266.0,3.0,2.0]|            4|[475.0,657.0,581....|[0.19467213114754...|       1.0|\n",
      "|[307.0,12.0,1.0]|            2|[163.0,156.0,291....|[0.08101391650099...|       4.0|\n",
      "|[218.0,16.0,1.0]|            4|[388.0,258.0,317....|[0.19715447154471...|       4.0|\n",
      "|[285.0,24.0,2.0]|            3|[214.0,128.0,98.0...|[0.31845238095238...|       0.0|\n",
      "|[266.0,36.0,2.0]|            4|[388.0,258.0,317....|[0.19715447154471...|       4.0|\n",
      "| [108.0,8.0,1.0]|            2|[25.0,56.0,52.0,5...|[0.11061946902654...|       3.0|\n",
      "|[307.0,36.0,1.0]|            3|[163.0,156.0,291....|[0.08101391650099...|       4.0|\n",
      "|[307.0,15.0,1.0]|            4|[163.0,156.0,291....|[0.08101391650099...|       4.0|\n",
      "| [20.0,60.0,1.0]|            2|[236.0,206.0,154....|[0.26077348066298...|       0.0|\n",
      "|[307.0,18.0,1.0]|            3|[163.0,156.0,291....|[0.08101391650099...|       4.0|\n",
      "| [307.0,1.0,1.0]|            1|[167.0,247.0,357....|[0.13180741910023...|       2.0|\n",
      "|[252.0,60.0,2.0]|            3|[388.0,258.0,317....|[0.19715447154471...|       4.0|\n",
      "| [285.0,6.0,2.0]|            2|[214.0,128.0,98.0...|[0.31845238095238...|       0.0|\n",
      "|  [88.0,2.0,1.0]|            3|[122.0,176.0,133....|[0.20469798657718...|       1.0|\n",
      "| [307.0,3.0,1.0]|            1|[45.0,145.0,200.0...|[0.05696202531645...|       3.0|\n",
      "| [307.0,1.0,1.0]|            1|[167.0,247.0,357....|[0.13180741910023...|       2.0|\n",
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            4|       4.0|\n",
      "|            4|       4.0|\n",
      "|            2|       4.0|\n",
      "|            1|       0.0|\n",
      "|            4|       1.0|\n",
      "|            2|       4.0|\n",
      "|            4|       4.0|\n",
      "|            3|       0.0|\n",
      "|            4|       4.0|\n",
      "|            2|       3.0|\n",
      "|            3|       4.0|\n",
      "|            4|       4.0|\n",
      "|            2|       0.0|\n",
      "|            3|       4.0|\n",
      "|            1|       2.0|\n",
      "|            3|       4.0|\n",
      "|            2|       0.0|\n",
      "|            3|       1.0|\n",
      "|            1|       3.0|\n",
      "|            1|       2.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "F1 score: 0.298\n",
      "+------------------------+---+---+---+---+---+\n",
      "|AdoptionSpeed_prediction|0.0|1.0|2.0|3.0|4.0|\n",
      "+------------------------+---+---+---+---+---+\n",
      "|                       3|143|142|127| 70|160|\n",
      "|                       0| 22| 27| 15|  3| 14|\n",
      "|                       1|208|160|133| 41| 77|\n",
      "|                       4|168| 67|132| 78|378|\n",
      "|                       2|218|177|206| 68|165|\n",
      "+------------------------+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "# Split the data into training and validation data\n",
    "train_data = finalized_data\n",
    "classifier = DecisionTreeClassifier( labelCol='AdoptionSpeed', featuresCol='features')\n",
    "classifier = classifier.fit(train_data) # Fit the model\n",
    "\n",
    "\n",
    "test_data = testfinalized_data\n",
    "results = classifier.transform(test_data) # Evaluate the model on the validation data\n",
    "results.show() # Show the predictions\n",
    "results.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "\n",
    "# Want to show the f1 score and confusion matrix\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AdoptionSpeed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(results)\n",
    "print(\"F1 score: %.3f\" % f1_score)\n",
    "\n",
    "# Confusion matrix\n",
    "results.crosstab('AdoptionSpeed', 'prediction').show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "|        features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "| [265.0,7.0,2.0]|            4|[4.30130519439516...|[0.21506525971975...|       4.0|\n",
      "|[266.0,24.0,2.0]|            4|[3.89876794043720...|[0.19493839702186...|       4.0|\n",
      "|[266.0,12.0,2.0]|            2|[3.89876794043720...|[0.19493839702186...|       4.0|\n",
      "|[195.0,60.0,1.0]|            1|[7.44879126264556...|[0.37243956313227...|       0.0|\n",
      "| [266.0,3.0,2.0]|            4|[4.23385838023537...|[0.21169291901176...|       1.0|\n",
      "|[307.0,12.0,1.0]|            2|[1.64190304309554...|[0.08209515215477...|       4.0|\n",
      "|[218.0,16.0,1.0]|            4|[4.56098088565224...|[0.22804904428261...|       4.0|\n",
      "|[285.0,24.0,2.0]|            3|[4.81435579691729...|[0.24071778984586...|       4.0|\n",
      "|[266.0,36.0,2.0]|            4|[3.65950492337921...|[0.18297524616896...|       4.0|\n",
      "| [108.0,8.0,1.0]|            2|[5.27956576120169...|[0.26397828806008...|       0.0|\n",
      "|[307.0,36.0,1.0]|            3|[1.63090014346762...|[0.08154500717338...|       4.0|\n",
      "|[307.0,15.0,1.0]|            4|[1.60455003727072...|[0.08022750186353...|       4.0|\n",
      "| [20.0,60.0,1.0]|            2|[5.08043654807815...|[0.25402182740390...|       0.0|\n",
      "|[307.0,18.0,1.0]|            3|[1.60455003727072...|[0.08022750186353...|       4.0|\n",
      "| [307.0,1.0,1.0]|            1|[2.51241098393077...|[0.12562054919653...|       2.0|\n",
      "|[252.0,60.0,2.0]|            3|[4.03264698851603...|[0.20163234942580...|       4.0|\n",
      "| [285.0,6.0,2.0]|            2|[6.69785990822317...|[0.33489299541115...|       0.0|\n",
      "|  [88.0,2.0,1.0]|            3|[4.55602988831168...|[0.22780149441558...|       1.0|\n",
      "| [307.0,3.0,1.0]|            1|[1.52580242134692...|[0.07629012106734...|       3.0|\n",
      "| [307.0,1.0,1.0]|            1|[2.51241098393077...|[0.12562054919653...|       2.0|\n",
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            4|       4.0|\n",
      "|            4|       4.0|\n",
      "|            2|       4.0|\n",
      "|            1|       0.0|\n",
      "|            4|       1.0|\n",
      "|            2|       4.0|\n",
      "|            4|       4.0|\n",
      "|            3|       4.0|\n",
      "|            4|       4.0|\n",
      "|            2|       0.0|\n",
      "|            3|       4.0|\n",
      "|            4|       4.0|\n",
      "|            2|       0.0|\n",
      "|            3|       4.0|\n",
      "|            1|       2.0|\n",
      "|            3|       4.0|\n",
      "|            2|       0.0|\n",
      "|            3|       1.0|\n",
      "|            1|       3.0|\n",
      "|            1|       2.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "F1 score: 0.300\n",
      "+------------------------+---+---+---+---+---+\n",
      "|AdoptionSpeed_prediction|0.0|1.0|2.0|3.0|4.0|\n",
      "+------------------------+---+---+---+---+---+\n",
      "|                       3|127|160|127| 49|179|\n",
      "|                       0| 13| 31| 15|  1| 21|\n",
      "|                       1|152|214|133| 22| 98|\n",
      "|                       4|109|117|132| 55|410|\n",
      "|                       2|147|247|206| 43|191|\n",
      "+------------------------+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "train_data = finalized_data\n",
    "classifier = RandomForestClassifier(labelCol='AdoptionSpeed', featuresCol='features')\n",
    "classifier = classifier.fit(train_data) # Fit the model\n",
    "\n",
    "\n",
    "test_data = testfinalized_data\n",
    "results = classifier.transform(test_data) # Evaluate the model on the validation data\n",
    "results.show() # Show the predictions\n",
    "results.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "\n",
    "# Want to show the f1 score and confusion matrix\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AdoptionSpeed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(results)\n",
    "print(\"F1 score: %.3f\" % f1_score)\n",
    "\n",
    "# Confusion matrix\n",
    "results.crosstab('AdoptionSpeed', 'prediction').show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "|        features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "| [265.0,7.0,2.0]|            4|[-46.974540850384...|[0.14402667045828...|       2.0|\n",
      "|[266.0,24.0,2.0]|            4|[-101.24812790298...|[0.17873348172516...|       4.0|\n",
      "|[266.0,12.0,2.0]|            2|[-62.971521419971...|[0.25457037136800...|       0.0|\n",
      "|[195.0,60.0,1.0]|            1|[-207.53567000969...|[0.00110149909586...|       4.0|\n",
      "| [266.0,3.0,2.0]|            4|[-34.264066557712...|[0.06978615073014...|       2.0|\n",
      "|[307.0,12.0,1.0]|            2|[-59.849431997550...|[0.19599104897496...|       3.0|\n",
      "|[218.0,16.0,1.0]|            4|[-68.301187210301...|[0.24240190122342...|       4.0|\n",
      "|[285.0,24.0,2.0]|            3|[-102.16762406796...|[0.19066671534541...|       4.0|\n",
      "|[266.0,36.0,2.0]|            4|[-139.52473438599...|[0.04484194761579...|       4.0|\n",
      "| [108.0,8.0,1.0]|            2|[-37.460050705060...|[0.26457353006534...|       4.0|\n",
      "|[307.0,36.0,1.0]|            3|[-136.40264496357...|[0.04475177372986...|       4.0|\n",
      "|[307.0,15.0,1.0]|            4|[-69.418583618303...|[0.24059649742956...|       4.0|\n",
      "| [20.0,60.0,1.0]|            2|[-199.06662638485...|[4.60390919166669...|       4.0|\n",
      "|[307.0,18.0,1.0]|            3|[-78.987735239056...|[0.24699024290453...|       4.0|\n",
      "| [307.0,1.0,1.0]|            1|[-24.762542721456...|[0.02910676910243...|       2.0|\n",
      "|[252.0,60.0,2.0]|            3|[-215.40042386203...|[0.00179573503378...|       4.0|\n",
      "| [285.0,6.0,2.0]|            2|[-44.752714343448...|[0.10597395072662...|       2.0|\n",
      "|  [88.0,2.0,1.0]|            3|[-17.353856763573...|[0.18378945931450...|       1.0|\n",
      "| [307.0,3.0,1.0]|            1|[-31.141977135291...|[0.04467685982069...|       2.0|\n",
      "| [307.0,1.0,1.0]|            1|[-24.762542721456...|[0.02910676910243...|       2.0|\n",
      "+----------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            4|       2.0|\n",
      "|            4|       4.0|\n",
      "|            2|       0.0|\n",
      "|            1|       4.0|\n",
      "|            4|       2.0|\n",
      "|            2|       3.0|\n",
      "|            4|       4.0|\n",
      "|            3|       4.0|\n",
      "|            4|       4.0|\n",
      "|            2|       4.0|\n",
      "|            3|       4.0|\n",
      "|            4|       4.0|\n",
      "|            2|       4.0|\n",
      "|            3|       4.0|\n",
      "|            1|       2.0|\n",
      "|            3|       4.0|\n",
      "|            2|       2.0|\n",
      "|            3|       1.0|\n",
      "|            1|       2.0|\n",
      "|            1|       2.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "F1 score: 0.235\n",
      "+------------------------+---+---+---+---+---+\n",
      "|AdoptionSpeed_prediction|0.0|1.0|2.0|3.0|4.0|\n",
      "+------------------------+---+---+---+---+---+\n",
      "|                       3| 30| 24|432| 25|131|\n",
      "|                       0|  7|  1| 54|  4| 15|\n",
      "|                       1| 23| 18|466|  5|107|\n",
      "|                       4| 47| 25|479| 44|228|\n",
      "|                       2| 29| 22|632| 19|132|\n",
      "+------------------------+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "train_data = finalized_data\n",
    "classifier = NaiveBayes(labelCol='AdoptionSpeed', featuresCol='features')\n",
    "classifier = classifier.fit(train_data) # Fit the model\n",
    "\n",
    "\n",
    "test_data = testfinalized_data\n",
    "results = classifier.transform(test_data) # Evaluate the model on the validation data\n",
    "results.show() # Show the predictions\n",
    "results.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "\n",
    "# Want to show the f1 score and confusion matrix\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AdoptionSpeed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(results)\n",
    "print(\"F1 score: %.3f\" % f1_score)\n",
    "\n",
    "# Confusion matrix\n",
    "results.crosstab('AdoptionSpeed', 'prediction').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
