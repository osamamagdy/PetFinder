{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMporting the libraries\n",
    "import pyspark\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 3 features:  'Type', 'Age', 'Breed1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pyspark to read the data and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training data:  10509\n",
      "Size of the test data:  4484\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To work with spark we need to create a spark session\n",
    "# Need to instal java\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('petfinder').getOrCreate()\n",
    "\n",
    "# Importing the dataset and split it into training and test data\n",
    "df_spark, df_spark_test = spark.read.csv('./train.csv', header=True, inferSchema=True).randomSplit([0.7, 0.3])\n",
    "\n",
    "######### For the training data #########\n",
    "# Convert the column \"AdoptionSpeed\" to integer\n",
    "df_spark = df_spark.withColumn(\"AdoptionSpeed\", df_spark[\"AdoptionSpeed\"].cast(\"integer\"))\n",
    "# Select the columns that we need ['Type', 'Age', 'Breed1']\n",
    "df_spark = df_spark.select(['Type', 'Age', 'Breed1', 'AdoptionSpeed'])\n",
    "\n",
    "######### For the test data #########\n",
    "# Convert the column \"AdoptionSpeed\" to integer\n",
    "df_spark_test = df_spark_test.withColumn(\"AdoptionSpeed\", df_spark_test[\"AdoptionSpeed\"].cast(\"integer\"))\n",
    "# Select the columns that we need ['Type', 'Age', 'Breed1']\n",
    "df_spark_test = df_spark_test.select(['Type', 'Age', 'Breed1', 'AdoptionSpeed'])\n",
    "\n",
    "\n",
    "\n",
    "## Print size of the data\n",
    "print(\"Size of the training data: \", df_spark.count())\n",
    "print(\"Size of the test data: \", df_spark_test.count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+-------------+\n",
      "|Type|Age|Breed1|AdoptionSpeed|\n",
      "+----+---+------+-------------+\n",
      "|   1|  0|   307|            1|\n",
      "|   1|  0|   307|            4|\n",
      "|   1|  0|   307|            2|\n",
      "|   1|  0|   307|            2|\n",
      "|   1|  0|   307|            4|\n",
      "|   1|  0|   307|            3|\n",
      "|   1|  0|   307|            4|\n",
      "|   1|  1|   128|            3|\n",
      "|   1|  1|   189|            1|\n",
      "|   1|  1|   189|            0|\n",
      "|   1|  1|   307|            2|\n",
      "|   1|  1|   307|            2|\n",
      "|   1|  1|   307|            4|\n",
      "|   1|  1|   307|            2|\n",
      "|   1|  1|   307|            3|\n",
      "|   1|  1|   307|            3|\n",
      "|   1|  1|   307|            1|\n",
      "|   1|  1|   307|            4|\n",
      "|   1|  1|   307|            3|\n",
      "|   1|  1|   307|            3|\n",
      "+----+---+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+---+------+-------------+\n",
      "|Type|Age|Breed1|AdoptionSpeed|\n",
      "+----+---+------+-------------+\n",
      "|   1|  0|   307|            1|\n",
      "|   1|  0|   307|            0|\n",
      "|   1|  1|   141|            4|\n",
      "|   1|  1|   173|            0|\n",
      "|   1|  1|   307|            2|\n",
      "|   1|  1|   307|            4|\n",
      "|   1|  1|   307|            1|\n",
      "|   1|  1|   307|            4|\n",
      "|   1|  1|   307|            1|\n",
      "|   1|  1|   307|            3|\n",
      "|   1|  1|   307|            3|\n",
      "|   1|  1|   307|            3|\n",
      "|   1|  1|   307|            2|\n",
      "|   1|  1|   307|            2|\n",
      "|   1|  1|   307|            1|\n",
      "|   1|  1|   307|            2|\n",
      "|   1|  1|   307|            3|\n",
      "|   1|  1|   307|            4|\n",
      "|   1|  1|   307|            4|\n",
      "|   1|  1|   307|            1|\n",
      "+----+---+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########### For the train dataset\n",
    "\n",
    "## Drop rows with missing values\n",
    "# df_spark.na.drop(how='all', thresh=10).show() \n",
    "    ### how='any' means drop rows with any missing value, how='all' means drop rows whose all values are missing\n",
    "    ### thresh=10 means drop rows whose number of missing values is greater than 10\n",
    "    ### subset=['Age'] means drop rows whose 'Age' value is missing\n",
    "df_spark = df_spark.na.drop(how= 'any' , subset=['AdoptionSpeed'])\n",
    "## Fill missing values with mean\n",
    "from pyspark.sql.functions import mean\n",
    "mean_val = df_spark.select(mean(df_spark['Age'])).collect()\n",
    "mean_age = mean_val[0][0]\n",
    "df_spark.na.fill(mean_age, subset=['Age']).show()\n",
    "\n",
    "########### For the test dataset\n",
    "\n",
    "df_spark_test = df_spark_test.na.drop(how= 'any' , subset=['AdoptionSpeed'])\n",
    "## Fill missing values with mean\n",
    "from pyspark.sql.functions import mean\n",
    "mean_val = df_spark_test.select(mean(df_spark_test['Age'])).collect()\n",
    "mean_age = mean_val[0][0]\n",
    "df_spark_test.na.fill(mean_age, subset=['Age']).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PySpark MLlib to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+-------------+---------------+\n",
      "|Type|Age|Breed1|AdoptionSpeed|       features|\n",
      "+----+---+------+-------------+---------------+\n",
      "|   1|  0|   307|            1|[307.0,0.0,1.0]|\n",
      "|   1|  0|   307|            4|[307.0,0.0,1.0]|\n",
      "|   1|  0|   307|            2|[307.0,0.0,1.0]|\n",
      "|   1|  0|   307|            2|[307.0,0.0,1.0]|\n",
      "|   1|  0|   307|            4|[307.0,0.0,1.0]|\n",
      "|   1|  0|   307|            3|[307.0,0.0,1.0]|\n",
      "|   1|  0|   307|            4|[307.0,0.0,1.0]|\n",
      "|   1|  1|   128|            3|[128.0,1.0,1.0]|\n",
      "|   1|  1|   189|            1|[189.0,1.0,1.0]|\n",
      "|   1|  1|   189|            0|[189.0,1.0,1.0]|\n",
      "|   1|  1|   307|            2|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            2|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            4|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            2|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            3|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            3|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            1|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            4|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            3|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            3|[307.0,1.0,1.0]|\n",
      "+----+---+------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+---+------+-------------+---------------+\n",
      "|Type|Age|Breed1|AdoptionSpeed|       features|\n",
      "+----+---+------+-------------+---------------+\n",
      "|   1|  0|   307|            1|[307.0,0.0,1.0]|\n",
      "|   1|  0|   307|            0|[307.0,0.0,1.0]|\n",
      "|   1|  1|   141|            4|[141.0,1.0,1.0]|\n",
      "|   1|  1|   173|            0|[173.0,1.0,1.0]|\n",
      "|   1|  1|   307|            2|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            4|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            1|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            4|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            1|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            3|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            3|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            3|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            2|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            2|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            1|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            2|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            3|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            4|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            4|[307.0,1.0,1.0]|\n",
      "|   1|  1|   307|            1|[307.0,1.0,1.0]|\n",
      "+----+---+------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, collect the features in a single column\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "#### For the train dataset\n",
    "featureassemble = VectorAssembler(inputCols=['Breed1','Age','Type'], outputCol='features')\n",
    "output = featureassemble.transform(df_spark) # This will create a new column called 'features' which is a vector of the selected columns (Type, Age2, Breed1) by the VectorAssembler\n",
    "output.show()\n",
    "\n",
    "#### For the test dataset\n",
    "testfeatureassemble = VectorAssembler(inputCols=['Breed1','Age','Type'], outputCol='features')\n",
    "testoutput = testfeatureassemble.transform(df_spark_test) # This will create a new column called 'features' which is a vector of the selected columns (Type, Age2, Breed1) by the VectorAssembler\n",
    "testoutput.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+\n",
      "|       features|AdoptionSpeed|\n",
      "+---------------+-------------+\n",
      "|[307.0,0.0,1.0]|            1|\n",
      "|[307.0,0.0,1.0]|            4|\n",
      "|[307.0,0.0,1.0]|            2|\n",
      "|[307.0,0.0,1.0]|            2|\n",
      "|[307.0,0.0,1.0]|            4|\n",
      "|[307.0,0.0,1.0]|            3|\n",
      "|[307.0,0.0,1.0]|            4|\n",
      "|[128.0,1.0,1.0]|            3|\n",
      "|[189.0,1.0,1.0]|            1|\n",
      "|[189.0,1.0,1.0]|            0|\n",
      "|[307.0,1.0,1.0]|            2|\n",
      "|[307.0,1.0,1.0]|            2|\n",
      "|[307.0,1.0,1.0]|            4|\n",
      "|[307.0,1.0,1.0]|            2|\n",
      "|[307.0,1.0,1.0]|            3|\n",
      "|[307.0,1.0,1.0]|            3|\n",
      "|[307.0,1.0,1.0]|            1|\n",
      "|[307.0,1.0,1.0]|            4|\n",
      "|[307.0,1.0,1.0]|            3|\n",
      "|[307.0,1.0,1.0]|            3|\n",
      "+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+-------------+\n",
      "|       features|AdoptionSpeed|\n",
      "+---------------+-------------+\n",
      "|[307.0,0.0,1.0]|            1|\n",
      "|[307.0,0.0,1.0]|            0|\n",
      "|[141.0,1.0,1.0]|            4|\n",
      "|[173.0,1.0,1.0]|            0|\n",
      "|[307.0,1.0,1.0]|            2|\n",
      "|[307.0,1.0,1.0]|            4|\n",
      "|[307.0,1.0,1.0]|            1|\n",
      "|[307.0,1.0,1.0]|            4|\n",
      "|[307.0,1.0,1.0]|            1|\n",
      "|[307.0,1.0,1.0]|            3|\n",
      "|[307.0,1.0,1.0]|            3|\n",
      "|[307.0,1.0,1.0]|            3|\n",
      "|[307.0,1.0,1.0]|            2|\n",
      "|[307.0,1.0,1.0]|            2|\n",
      "|[307.0,1.0,1.0]|            1|\n",
      "|[307.0,1.0,1.0]|            2|\n",
      "|[307.0,1.0,1.0]|            3|\n",
      "|[307.0,1.0,1.0]|            4|\n",
      "|[307.0,1.0,1.0]|            4|\n",
      "|[307.0,1.0,1.0]|            1|\n",
      "+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the features and the target column\n",
    "\n",
    "#### For the train dataset\n",
    "finalized_data = output.select('features', 'AdoptionSpeed') # Select the features and the target column\n",
    "finalized_data.show()\n",
    "\n",
    "#### For the test dataset\n",
    "testfinalized_data = testoutput.select('features', 'AdoptionSpeed') # Select the features and the target column\n",
    "testfinalized_data.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|       features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|[307.0,0.0,1.0]|            1|[3.85593289186591...|[0.01547177856361...|       4.0|\n",
      "|[307.0,0.0,1.0]|            0|[3.85593289186591...|[0.01547177856361...|       4.0|\n",
      "|[141.0,1.0,1.0]|            4|[4.30374095429116...|[0.03338936633175...|       1.0|\n",
      "|[173.0,1.0,1.0]|            0|[4.21990095186108...|[0.02930485903556...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            4|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            1|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            4|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            1|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            3|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            3|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            3|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            2|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            2|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            1|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            2|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            3|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            4|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            4|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "|[307.0,1.0,1.0]|            1|[3.86882094168511...|[0.01542103828638...|       4.0|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            1|       4.0|\n",
      "|            0|       4.0|\n",
      "|            4|       1.0|\n",
      "|            0|       2.0|\n",
      "|            2|       4.0|\n",
      "|            4|       4.0|\n",
      "|            1|       4.0|\n",
      "|            4|       4.0|\n",
      "|            1|       4.0|\n",
      "|            3|       4.0|\n",
      "|            3|       4.0|\n",
      "|            3|       4.0|\n",
      "|            2|       4.0|\n",
      "|            2|       4.0|\n",
      "|            1|       4.0|\n",
      "|            2|       4.0|\n",
      "|            3|       4.0|\n",
      "|            4|       4.0|\n",
      "|            4|       4.0|\n",
      "|            1|       4.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "F1 score: 0.238\n",
      "+------------------------+---+---+---+---+\n",
      "|AdoptionSpeed_prediction|1.0|2.0|3.0|4.0|\n",
      "+------------------------+---+---+---+---+\n",
      "|                       7|  0|  0|  0|  2|\n",
      "|               152880177|  0|  0|  0|  1|\n",
      "|                      15|  0|  0|  0|  1|\n",
      "|                      11|  0|  1|  0|  0|\n",
      "|                       3| 61|357| 26|510|\n",
      "|                       8|  1|  0|  0|  2|\n",
      "|                       0|  6| 61|  4| 53|\n",
      "|                       5|  1|  0|  0|  3|\n",
      "|                       6|  0|  1|  0|  1|\n",
      "|                       9|  0|  1|  0|  0|\n",
      "|                       1| 58|458| 22|372|\n",
      "|                       4| 34|341| 23|808|\n",
      "|                      12|  0|  1|  0|  0|\n",
      "|                       2| 64|445| 26|660|\n",
      "+------------------------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Split the data into training and validation data\n",
    "train_data = finalized_data\n",
    "classifier = LogisticRegression\n",
    "classifier = LogisticRegression(labelCol='AdoptionSpeed').fit(train_data) # Fit the model\n",
    "\n",
    "\n",
    "test_data = testfinalized_data\n",
    "results = classifier.evaluate(test_data) # Evaluate the model on the validation data\n",
    "results.predictions.show() # Show the predictions\n",
    "results.predictions.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "\n",
    "# Want to show the f1 score and confusion matrix\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AdoptionSpeed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(results.predictions)\n",
    "print(\"F1 score: %.3f\" % f1_score)\n",
    "\n",
    "# Confusion matrix\n",
    "results.predictions.crosstab('AdoptionSpeed', 'prediction').show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|       features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|[307.0,0.0,1.0]|            1|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,0.0,1.0]|            0|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[141.0,1.0,1.0]|            4|[11.0,64.0,66.0,7...|[0.04641350210970...|       3.0|\n",
      "|[173.0,1.0,1.0]|            0|[11.0,64.0,66.0,7...|[0.04641350210970...|       3.0|\n",
      "|[307.0,1.0,1.0]|            2|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[12.0,177.0,281.0...|[0.01459854014598...|       2.0|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            1|       2.0|\n",
      "|            0|       2.0|\n",
      "|            4|       3.0|\n",
      "|            0|       3.0|\n",
      "|            2|       2.0|\n",
      "|            4|       2.0|\n",
      "|            1|       2.0|\n",
      "|            4|       2.0|\n",
      "|            1|       2.0|\n",
      "|            3|       2.0|\n",
      "|            3|       2.0|\n",
      "|            3|       2.0|\n",
      "|            2|       2.0|\n",
      "|            2|       2.0|\n",
      "|            1|       2.0|\n",
      "|            2|       2.0|\n",
      "|            3|       2.0|\n",
      "|            4|       2.0|\n",
      "|            4|       2.0|\n",
      "|            1|       2.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "F1 score: 0.300\n",
      "+------------------------+---+---+---+---+\n",
      "|AdoptionSpeed_prediction|1.0|2.0|3.0|4.0|\n",
      "+------------------------+---+---+---+---+\n",
      "|                       7|  0|  0|  1|  1|\n",
      "|               152880177|  0|  0|  0|  1|\n",
      "|                      15|  0|  1|  0|  0|\n",
      "|                      11|  0|  0|  0|  1|\n",
      "|                       3| 88|464| 42|360|\n",
      "|                       8|  1|  1|  0|  1|\n",
      "|                       0| 22| 62|  2| 38|\n",
      "|                       5|  1|  0|  0|  3|\n",
      "|                       6|  0|  1|  0|  1|\n",
      "|                       9|  0|  1|  0|  0|\n",
      "|                       1|125|493| 33|259|\n",
      "|                       4| 88|328| 15|775|\n",
      "|                      12|  0|  1|  0|  0|\n",
      "|                       2|114|621| 50|410|\n",
      "+------------------------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "# Split the data into training and validation data\n",
    "train_data = finalized_data\n",
    "classifier = DecisionTreeClassifier( labelCol='AdoptionSpeed', featuresCol='features')\n",
    "classifier = classifier.fit(train_data) # Fit the model\n",
    "\n",
    "\n",
    "test_data = testfinalized_data\n",
    "results = classifier.transform(test_data) # Evaluate the model on the validation data\n",
    "results.show() # Show the predictions\n",
    "results.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "\n",
    "# Want to show the f1 score and confusion matrix\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AdoptionSpeed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(results)\n",
    "print(\"F1 score: %.3f\" % f1_score)\n",
    "\n",
    "# Confusion matrix\n",
    "results.crosstab('AdoptionSpeed', 'prediction').show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|       features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|[307.0,0.0,1.0]|            1|[0.32194941714301...|[0.01609747085715...|       2.0|\n",
      "|[307.0,0.0,1.0]|            0|[0.32194941714301...|[0.01609747085715...|       2.0|\n",
      "|[141.0,1.0,1.0]|            4|[0.76637273249964...|[0.03831863662498...|       1.0|\n",
      "|[173.0,1.0,1.0]|            0|[0.76637273249964...|[0.03831863662498...|       1.0|\n",
      "|[307.0,1.0,1.0]|            2|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[0.34223752902365...|[0.01711187645118...|       2.0|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            1|       2.0|\n",
      "|            0|       2.0|\n",
      "|            4|       1.0|\n",
      "|            0|       1.0|\n",
      "|            2|       2.0|\n",
      "|            4|       2.0|\n",
      "|            1|       2.0|\n",
      "|            4|       2.0|\n",
      "|            1|       2.0|\n",
      "|            3|       2.0|\n",
      "|            3|       2.0|\n",
      "|            3|       2.0|\n",
      "|            2|       2.0|\n",
      "|            2|       2.0|\n",
      "|            1|       2.0|\n",
      "|            2|       2.0|\n",
      "|            3|       2.0|\n",
      "|            4|       2.0|\n",
      "|            4|       2.0|\n",
      "|            1|       2.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "F1 score: 0.305\n",
      "+------------------------+---+---+---+---+\n",
      "|AdoptionSpeed_prediction|1.0|2.0|3.0|4.0|\n",
      "+------------------------+---+---+---+---+\n",
      "|                       7|  0|  1|  0|  1|\n",
      "|               152880177|  0|  0|  0|  1|\n",
      "|                      15|  0|  1|  0|  0|\n",
      "|                      11|  0|  0|  0|  1|\n",
      "|                       3|121|483| 30|320|\n",
      "|                       8|  0|  2|  0|  1|\n",
      "|                       0| 26| 64|  1| 33|\n",
      "|                       5|  1|  0|  0|  3|\n",
      "|                       6|  0|  1|  0|  1|\n",
      "|                       9|  0|  1|  0|  0|\n",
      "|                       1|170|501| 23|216|\n",
      "|                       4|104|367|  9|726|\n",
      "|                      12|  0|  1|  0|  0|\n",
      "|                       2|163|644| 26|362|\n",
      "+------------------------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "train_data = finalized_data\n",
    "classifier = RandomForestClassifier(labelCol='AdoptionSpeed', featuresCol='features')\n",
    "classifier = classifier.fit(train_data) # Fit the model\n",
    "\n",
    "\n",
    "test_data = testfinalized_data\n",
    "results = classifier.transform(test_data) # Evaluate the model on the validation data\n",
    "results.show() # Show the predictions\n",
    "results.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "\n",
    "# Want to show the f1 score and confusion matrix\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AdoptionSpeed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(results)\n",
    "print(\"F1 score: %.3f\" % f1_score)\n",
    "\n",
    "# Confusion matrix\n",
    "results.crosstab('AdoptionSpeed', 'prediction').show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|       features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|[307.0,0.0,1.0]|            1|[-22.619651984454...|[0.00524808483129...|       2.0|\n",
      "|[307.0,0.0,1.0]|            0|[-22.619651984454...|[0.00524808483129...|       2.0|\n",
      "|[141.0,1.0,1.0]|            4|[-18.365367911113...|[0.01977398639212...|       2.0|\n",
      "|[173.0,1.0,1.0]|            0|[-19.814951597034...|[0.01649168010014...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            2|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            3|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            4|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "|[307.0,1.0,1.0]|            1|[-25.885083281829...|[0.00663321920203...|       2.0|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            1|       2.0|\n",
      "|            0|       2.0|\n",
      "|            4|       2.0|\n",
      "|            0|       2.0|\n",
      "|            2|       2.0|\n",
      "|            4|       2.0|\n",
      "|            1|       2.0|\n",
      "|            4|       2.0|\n",
      "|            1|       2.0|\n",
      "|            3|       2.0|\n",
      "|            3|       2.0|\n",
      "|            3|       2.0|\n",
      "|            2|       2.0|\n",
      "|            2|       2.0|\n",
      "|            1|       2.0|\n",
      "|            2|       2.0|\n",
      "|            3|       2.0|\n",
      "|            4|       2.0|\n",
      "|            4|       2.0|\n",
      "|            1|       2.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "F1 score: 0.191\n",
      "+------------------------+---+---+---+---+\n",
      "|AdoptionSpeed_prediction|2.0|3.0|4.0|8.0|\n",
      "+------------------------+---+---+---+---+\n",
      "|                       7|  0|  1|  0|  1|\n",
      "|               152880177|  1|  0|  0|  0|\n",
      "|                      15|  1|  0|  0|  0|\n",
      "|                      11|  1|  0|  0|  0|\n",
      "|                       3|736| 20|103| 95|\n",
      "|                       8|  3|  0|  0|  0|\n",
      "|                       0| 85|  1| 20| 18|\n",
      "|                       5|  1|  1|  2|  0|\n",
      "|                       6|  1|  1|  0|  0|\n",
      "|                       9|  1|  0|  0|  0|\n",
      "|                       1|726|  5| 99| 80|\n",
      "|                       4|761| 53|226|166|\n",
      "|                      12|  1|  0|  0|  0|\n",
      "|                       2|927| 22|128|118|\n",
      "+------------------------+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "train_data = finalized_data\n",
    "classifier = NaiveBayes(labelCol='AdoptionSpeed', featuresCol='features')\n",
    "classifier = classifier.fit(train_data) # Fit the model\n",
    "\n",
    "\n",
    "test_data = testfinalized_data\n",
    "results = classifier.transform(test_data) # Evaluate the model on the validation data\n",
    "results.show() # Show the predictions\n",
    "results.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "\n",
    "# Want to show the f1 score and confusion matrix\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AdoptionSpeed\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(results)\n",
    "print(\"F1 score: %.3f\" % f1_score)\n",
    "\n",
    "# Confusion matrix\n",
    "results.crosstab('AdoptionSpeed', 'prediction').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
