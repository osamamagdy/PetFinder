{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMporting the libraries\n",
    "import pyspark\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 3 features:  'Type', 'Age', 'Breed1'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pyspark to read the data and process it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To work with spark we need to create a spark session\n",
    "# Need to instal java\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('petfinder').getOrCreate()\n",
    "# Read a dataset with spark\n",
    "df_spark = spark.read.csv('./train.csv', header=True, inferSchema=True)\n",
    "# Header = True, inferSchema = True, means that the first row is the header and the schema is inferred (if schema is not inferred, all columns will be read as string)\n",
    "# Convert the column \"AdoptionSpeed\" to integer\n",
    "df_spark = df_spark.withColumn(\"AdoptionSpeed\", df_spark[\"AdoptionSpeed\"].cast(\"integer\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+---+------+------+------+------+------+------+------------+---------+----------+--------+----------+------+--------+---+-----+--------------------+--------+--------------------+---------+--------+-------------+\n",
      "|Type|                Name|Age|Breed1|Breed2|Gender|Color1|Color2|Color3|MaturitySize|FurLength|Vaccinated|Dewormed|Sterilized|Health|Quantity|Fee|State|           RescuerID|VideoAmt|         Description|    PetID|PhotoAmt|AdoptionSpeed|\n",
      "+----+--------------------+---+------+------+------+------+------+------+------------+---------+----------+--------+----------+------+--------+---+-----+--------------------+--------+--------------------+---------+--------+-------------+\n",
      "|   2|              Nibble|  3|   299|     0|     1|     1|     7|     0|           1|        1|         2|       2|         2|     1|       1|100|41326|8480853f516546f6c...|       0|Nibble is a 3+ mo...|86e1089a3|     1.0|            2|\n",
      "|   2|         No Name Yet|  1|   265|     0|     1|     1|     2|     0|           2|        2|         3|       3|         3|     1|       1|  0|41401|3082c7125d8fb66f7...|       0|I just found it a...|6296e909a|     2.0|            0|\n",
      "|   1|              Brisco|  1|   307|     0|     1|     2|     7|     0|           2|        2|         1|       1|         2|     1|       1|  0|41326|fa90fa5b1ee11c869...|       0|Their pregnant mo...|3422e4906|     7.0|            3|\n",
      "|   1|                Miko|  4|   307|     0|     2|     1|     2|     0|           2|        1|         1|       1|         2|     1|       1|150|41401|9238e4f44c71a7528...|       0|Good guard dog, v...|5842f1ff5|     8.0|            2|\n",
      "|   1|              Hunter|  1|   307|     0|     1|     1|     0|     0|           2|        1|         2|       2|         2|     1|       1|  0|41326|95481e953f8aed9ec...|       0|This handsome yet...|850a43f90|     3.0|            2|\n",
      "|   2|                null|  3|   266|     0|     2|     5|     6|     0|           2|        1|         2|       2|         2|     1|       1|  0|41326|22fe332bf9c924d47...|       0|This is a stray k...|d24c30b4b|     2.0|            2|\n",
      "|   2|               BULAT| 12|   264|   264|     1|     1|     0|     0|           2|        3|         2|       2|         3|     1|       1|300|41326|1e0b5a458b5b77f5a...|       0|anyone within the...|1caa6fcdb|     3.0|            1|\n",
      "|   1|Siu Pak & Her 6 P...|  0|   307|     0|     2|     1|     2|     7|           2|        1|         2|       2|         2|     1|       6|  0|41326|1fba5f6e548094625...|       0|Siu Pak just give...|97aa9eeac|     9.0|            3|\n",
      "|   2|                null|  2|   265|     0|     2|     6|     0|     0|           2|        2|         2|       2|         2|     1|       1|  0|41326|d8af7afece7133447...|       0|healthy and activ...|c06d167ca|     6.0|            1|\n",
      "|   2|               Kitty| 12|   265|     0|     2|     1|     7|     0|           2|        2|         3|       3|         3|     1|       1|  0|41326|1f3f36e4b18e94855...|       0|Very manja and ge...|7a0942d61|     2.0|            4|\n",
      "|   1|                Bear|  2|   307|     0|     1|     1|     2|     7|           2|        1|         2|       1|         2|     1|       1|  0|41401|9238e4f44c71a7528...|       0|For serious adopt...|8b693ca84|     7.0|            1|\n",
      "|   2|                Kali|  3|   264|     0|     2|     1|     2|     5|           3|        3|         1|       1|         2|     1|       1| 50|41326|a9caef3f98e67bfac...|       0|Kali is a super p...|8e76c8e39|     2.0|            1|\n",
      "|   1|              Peanut|  2|   307|     0|     1|     2|     5|     6|           2|        3|         1|       1|         2|     1|       1|  0|41326|db784cbcf321e1d88...|       0|Peanut was an abu...|aaedd873d|     1.0|            2|\n",
      "|   2|2 Mths Old Cute K...|  2|   265|     0|     3|     1|     6|     7|           1|        2|         2|       2|         3|     1|       7|  0|41326|2c118b2a1d1b4cf1f...|       0|Hi Pet Lovers! Th...|4a9793dfb|     1.0|            1|\n",
      "|   1|            Lost Dog|  3|   307|     0|     2|     2|     5|     7|           2|        2|         3|       3|         3|     1|       1|  0|41401|b609c40c6c840db20...|       0|Lost Dog Found (B...|c02be41e6|     2.0|            2|\n",
      "|   1|                 Max| 78|   218|   205|     1|     1|     7|     0|           2|        2|         3|       3|         3|     1|       1|  0|41326|39112c637c80a6055...|       0|We moved out of o...|1fd342e17|     2.0|            4|\n",
      "|   2|             Brownie|  6|   266|     0|     2|     2|     0|     0|           1|        1|         1|       1|         1|     1|       1|  0|41326|58e3aa0b4b78e8879...|       0|to be spayed on /...|b38a74866|     1.0|            3|\n",
      "|   1|             Blackie|  8|   307|   307|     2|     2|     0|     0|           2|        1|         2|       1|         1|     1|       1| 10|41330|4e3dec1544d1407fc...|       0|shes active... sh...|f9d07d5fa|     2.0|            4|\n",
      "|   1|              Beauty|  2|   307|     0|     2|     1|     0|     0|           2|        1|         2|       1|         2|     1|       1|  0|41401|9238e4f44c71a7528...|       0|This cutie dumped...|1c92ce464|     8.0|            2|\n",
      "|   2|                null|  1|   266|     0|     3|     1|     2|     7|           1|        1|         2|       2|         2|     1|       5|  0|41326|b752f78276215f445...|       0|Birth Date: Oct 3...|b10e7605a|     1.0|            4|\n",
      "+----+--------------------+---+------+------+------+------+------+------+------------+---------+----------+--------+----------+------+--------+---+-----+--------------------+--------+--------------------+---------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Drop rows with missing values\n",
    "# df_spark.na.drop(how='all', thresh=10).show() \n",
    "    ### how='any' means drop rows with any missing value, how='all' means drop rows whose all values are missing\n",
    "    ### thresh=10 means drop rows whose number of missing values is greater than 10\n",
    "    ### subset=['Age'] means drop rows whose 'Age' value is missing\n",
    "df_spark = df_spark.na.drop(how= 'any' , subset=['AdoptionSpeed'])\n",
    "## Fill missing values with mean\n",
    "from pyspark.sql.functions import mean\n",
    "mean_val = df_spark.select(mean(df_spark['Age'])).collect()\n",
    "mean_age = mean_val[0][0]\n",
    "df_spark.na.fill(mean_age, subset=['Age']).show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PySpark MLlib to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+---+------+------+------+------+------+------+------------+---------+----------+--------+----------+------+--------+---+-----+--------------------+--------+--------------------+---------+--------+-------------+----------------+\n",
      "|Type|                Name|Age|Breed1|Breed2|Gender|Color1|Color2|Color3|MaturitySize|FurLength|Vaccinated|Dewormed|Sterilized|Health|Quantity|Fee|State|           RescuerID|VideoAmt|         Description|    PetID|PhotoAmt|AdoptionSpeed|        features|\n",
      "+----+--------------------+---+------+------+------+------+------+------+------------+---------+----------+--------+----------+------+--------+---+-----+--------------------+--------+--------------------+---------+--------+-------------+----------------+\n",
      "|   2|              Nibble|  3|   299|     0|     1|     1|     7|     0|           1|        1|         2|       2|         2|     1|       1|100|41326|8480853f516546f6c...|       0|Nibble is a 3+ mo...|86e1089a3|     1.0|            2| [299.0,3.0,2.0]|\n",
      "|   2|         No Name Yet|  1|   265|     0|     1|     1|     2|     0|           2|        2|         3|       3|         3|     1|       1|  0|41401|3082c7125d8fb66f7...|       0|I just found it a...|6296e909a|     2.0|            0| [265.0,1.0,2.0]|\n",
      "|   1|              Brisco|  1|   307|     0|     1|     2|     7|     0|           2|        2|         1|       1|         2|     1|       1|  0|41326|fa90fa5b1ee11c869...|       0|Their pregnant mo...|3422e4906|     7.0|            3| [307.0,1.0,1.0]|\n",
      "|   1|                Miko|  4|   307|     0|     2|     1|     2|     0|           2|        1|         1|       1|         2|     1|       1|150|41401|9238e4f44c71a7528...|       0|Good guard dog, v...|5842f1ff5|     8.0|            2| [307.0,4.0,1.0]|\n",
      "|   1|              Hunter|  1|   307|     0|     1|     1|     0|     0|           2|        1|         2|       2|         2|     1|       1|  0|41326|95481e953f8aed9ec...|       0|This handsome yet...|850a43f90|     3.0|            2| [307.0,1.0,1.0]|\n",
      "|   2|                null|  3|   266|     0|     2|     5|     6|     0|           2|        1|         2|       2|         2|     1|       1|  0|41326|22fe332bf9c924d47...|       0|This is a stray k...|d24c30b4b|     2.0|            2| [266.0,3.0,2.0]|\n",
      "|   2|               BULAT| 12|   264|   264|     1|     1|     0|     0|           2|        3|         2|       2|         3|     1|       1|300|41326|1e0b5a458b5b77f5a...|       0|anyone within the...|1caa6fcdb|     3.0|            1|[264.0,12.0,2.0]|\n",
      "|   1|Siu Pak & Her 6 P...|  0|   307|     0|     2|     1|     2|     7|           2|        1|         2|       2|         2|     1|       6|  0|41326|1fba5f6e548094625...|       0|Siu Pak just give...|97aa9eeac|     9.0|            3| [307.0,0.0,1.0]|\n",
      "|   2|                null|  2|   265|     0|     2|     6|     0|     0|           2|        2|         2|       2|         2|     1|       1|  0|41326|d8af7afece7133447...|       0|healthy and activ...|c06d167ca|     6.0|            1| [265.0,2.0,2.0]|\n",
      "|   2|               Kitty| 12|   265|     0|     2|     1|     7|     0|           2|        2|         3|       3|         3|     1|       1|  0|41326|1f3f36e4b18e94855...|       0|Very manja and ge...|7a0942d61|     2.0|            4|[265.0,12.0,2.0]|\n",
      "|   1|                Bear|  2|   307|     0|     1|     1|     2|     7|           2|        1|         2|       1|         2|     1|       1|  0|41401|9238e4f44c71a7528...|       0|For serious adopt...|8b693ca84|     7.0|            1| [307.0,2.0,1.0]|\n",
      "|   2|                Kali|  3|   264|     0|     2|     1|     2|     5|           3|        3|         1|       1|         2|     1|       1| 50|41326|a9caef3f98e67bfac...|       0|Kali is a super p...|8e76c8e39|     2.0|            1| [264.0,3.0,2.0]|\n",
      "|   1|              Peanut|  2|   307|     0|     1|     2|     5|     6|           2|        3|         1|       1|         2|     1|       1|  0|41326|db784cbcf321e1d88...|       0|Peanut was an abu...|aaedd873d|     1.0|            2| [307.0,2.0,1.0]|\n",
      "|   2|2 Mths Old Cute K...|  2|   265|     0|     3|     1|     6|     7|           1|        2|         2|       2|         3|     1|       7|  0|41326|2c118b2a1d1b4cf1f...|       0|Hi Pet Lovers! Th...|4a9793dfb|     1.0|            1| [265.0,2.0,2.0]|\n",
      "|   1|            Lost Dog|  3|   307|     0|     2|     2|     5|     7|           2|        2|         3|       3|         3|     1|       1|  0|41401|b609c40c6c840db20...|       0|Lost Dog Found (B...|c02be41e6|     2.0|            2| [307.0,3.0,1.0]|\n",
      "|   1|                 Max| 78|   218|   205|     1|     1|     7|     0|           2|        2|         3|       3|         3|     1|       1|  0|41326|39112c637c80a6055...|       0|We moved out of o...|1fd342e17|     2.0|            4|[218.0,78.0,1.0]|\n",
      "|   2|             Brownie|  6|   266|     0|     2|     2|     0|     0|           1|        1|         1|       1|         1|     1|       1|  0|41326|58e3aa0b4b78e8879...|       0|to be spayed on /...|b38a74866|     1.0|            3| [266.0,6.0,2.0]|\n",
      "|   1|             Blackie|  8|   307|   307|     2|     2|     0|     0|           2|        1|         2|       1|         1|     1|       1| 10|41330|4e3dec1544d1407fc...|       0|shes active... sh...|f9d07d5fa|     2.0|            4| [307.0,8.0,1.0]|\n",
      "|   1|              Beauty|  2|   307|     0|     2|     1|     0|     0|           2|        1|         2|       1|         2|     1|       1|  0|41401|9238e4f44c71a7528...|       0|This cutie dumped...|1c92ce464|     8.0|            2| [307.0,2.0,1.0]|\n",
      "|   2|                null|  1|   266|     0|     3|     1|     2|     7|           1|        1|         2|       2|         2|     1|       5|  0|41326|b752f78276215f445...|       0|Birth Date: Oct 3...|b10e7605a|     1.0|            4| [266.0,1.0,2.0]|\n",
      "+----+--------------------+---+------+------+------+------+------+------+------------+---------+----------+--------+----------+------+--------+---+-----+--------------------+--------+--------------------+---------+--------+-------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "featureassemble = VectorAssembler(inputCols=['Breed1','Age','Type'], outputCol='features')\n",
    "output = featureassemble.transform(df_spark) # This will create a new column called 'features' which is a vector of the selected columns (Type, Age2, Breed1) by the VectorAssembler\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+\n",
      "|        features|AdoptionSpeed|\n",
      "+----------------+-------------+\n",
      "| [299.0,3.0,2.0]|            2|\n",
      "| [265.0,1.0,2.0]|            0|\n",
      "| [307.0,1.0,1.0]|            3|\n",
      "| [307.0,4.0,1.0]|            2|\n",
      "| [307.0,1.0,1.0]|            2|\n",
      "| [266.0,3.0,2.0]|            2|\n",
      "|[264.0,12.0,2.0]|            1|\n",
      "| [307.0,0.0,1.0]|            3|\n",
      "| [265.0,2.0,2.0]|            1|\n",
      "|[265.0,12.0,2.0]|            4|\n",
      "| [307.0,2.0,1.0]|            1|\n",
      "| [264.0,3.0,2.0]|            1|\n",
      "| [307.0,2.0,1.0]|            2|\n",
      "| [265.0,2.0,2.0]|            1|\n",
      "| [307.0,3.0,1.0]|            2|\n",
      "|[218.0,78.0,1.0]|            4|\n",
      "| [266.0,6.0,2.0]|            3|\n",
      "| [307.0,8.0,1.0]|            4|\n",
      "| [307.0,2.0,1.0]|            2|\n",
      "| [266.0,1.0,2.0]|            4|\n",
      "+----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data = output.select('features', 'AdoptionSpeed') # Select the features and the target column\n",
    "finalized_data.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|       features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|  [0.0,2.0,1.0]|            3|[4.50654175975770...|[0.04978538642926...|       1.0|\n",
      "|  [0.0,2.0,1.0]|            3|[4.50654175975770...|[0.04978538642926...|       1.0|\n",
      "|  [0.0,3.0,2.0]|            2|[6.63322771602572...|[0.08340635650503...|       1.0|\n",
      "|  [0.0,4.0,1.0]|            4|[4.56675914155921...|[0.05038444511846...|       1.0|\n",
      "| [0.0,72.0,1.0]|            4|[6.61415012281041...|[0.06729387890644...|       1.0|\n",
      "|  [1.0,5.0,1.0]|            4|[4.59372545418808...|[0.05059119305873...|       1.0|\n",
      "|  [5.0,0.0,1.0]|            1|[4.43061248659681...|[0.04874942113830...|       1.0|\n",
      "| [5.0,24.0,1.0]|            4|[5.15322106821489...|[0.05569110923999...|       1.0|\n",
      "| [7.0,14.0,1.0]|            4|[4.84584940266360...|[0.05263461833361...|       1.0|\n",
      "|[10.0,60.0,1.0]|            3|[6.22142204928262...|[0.06352671512164...|       1.0|\n",
      "|[10.0,84.0,1.0]|            3|[6.94403063090069...|[0.06633382659467...|       1.0|\n",
      "| [11.0,1.0,1.0]|            4|[4.44186690786631...|[0.04851009057049...|       1.0|\n",
      "| [15.0,1.0,1.0]|            1|[4.42929739477881...|[0.04815064456036...|       1.0|\n",
      "| [15.0,1.0,1.0]|            3|[4.42929739477881...|[0.04815064456036...|       1.0|\n",
      "| [15.0,1.0,1.0]|            3|[4.42929739477881...|[0.04815064456036...|       1.0|\n",
      "| [15.0,1.0,2.0]|            4|[6.52587466014607...|[0.07881647727756...|       1.0|\n",
      "| [15.0,4.0,1.0]|            4|[4.51962346748106...|[0.04899973424241...|       1.0|\n",
      "|[15.0,42.0,1.0]|            4|[5.66375372170968...|[0.05902059029219...|       1.0|\n",
      "|[16.0,17.0,1.0]|            4|[4.90789407091898...|[0.05251418869472...|       1.0|\n",
      "| [17.0,5.0,1.0]|            1|[4.54344740183806...|[0.04909221204151...|       1.0|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            3|       1.0|\n",
      "|            3|       1.0|\n",
      "|            2|       1.0|\n",
      "|            4|       1.0|\n",
      "|            4|       1.0|\n",
      "|            4|       1.0|\n",
      "|            1|       1.0|\n",
      "|            4|       1.0|\n",
      "|            4|       1.0|\n",
      "|            3|       1.0|\n",
      "|            3|       1.0|\n",
      "|            4|       1.0|\n",
      "|            1|       1.0|\n",
      "|            3|       1.0|\n",
      "|            3|       1.0|\n",
      "|            4|       1.0|\n",
      "|            4|       1.0|\n",
      "|            4|       1.0|\n",
      "|            4|       1.0|\n",
      "|            1|       1.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3114915536701765"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Split the data into training and validation data\n",
    "train_data, validation_data = finalized_data.randomSplit([0.1, 0.9])\n",
    "classifier = LogisticRegression\n",
    "classifier = LogisticRegression(labelCol='AdoptionSpeed').fit(train_data) # Fit the model\n",
    "results = classifier.evaluate(validation_data) # Evaluate the model on the validation data\n",
    "results.predictions.show() # Show the predictions\n",
    "results.predictions.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "results.accuracy # Show the accuracy of the model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|       features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|  [0.0,2.0,1.0]|            3|[13.0,77.0,113.0,...|[0.03746397694524...|       2.0|\n",
      "|  [0.0,2.0,1.0]|            3|[13.0,77.0,113.0,...|[0.03746397694524...|       2.0|\n",
      "|  [0.0,3.0,2.0]|            2|[13.0,77.0,113.0,...|[0.03746397694524...|       2.0|\n",
      "|  [0.0,4.0,1.0]|            4|[0.0,3.0,3.0,8.0,...|[0.0,0.1764705882...|       3.0|\n",
      "| [0.0,72.0,1.0]|            4|[8.0,39.0,50.0,29...|[0.04878048780487...|       2.0|\n",
      "|  [1.0,5.0,1.0]|            4|[0.0,3.0,3.0,8.0,...|[0.0,0.1764705882...|       3.0|\n",
      "|  [5.0,0.0,1.0]|            1|[1.0,1.0,0.0,0.0,...|[0.5,0.5,0.0,0.0,...|       0.0|\n",
      "| [5.0,24.0,1.0]|            4|[8.0,39.0,50.0,29...|[0.04878048780487...|       2.0|\n",
      "| [7.0,14.0,1.0]|            4|[8.0,39.0,50.0,29...|[0.04878048780487...|       2.0|\n",
      "|[10.0,60.0,1.0]|            3|[8.0,39.0,50.0,29...|[0.04878048780487...|       2.0|\n",
      "|[10.0,84.0,1.0]|            3|[8.0,39.0,50.0,29...|[0.04878048780487...|       2.0|\n",
      "| [11.0,1.0,1.0]|            4|[13.0,77.0,113.0,...|[0.03746397694524...|       2.0|\n",
      "| [15.0,1.0,1.0]|            1|[13.0,77.0,113.0,...|[0.03746397694524...|       2.0|\n",
      "| [15.0,1.0,1.0]|            1|[13.0,77.0,113.0,...|[0.03746397694524...|       2.0|\n",
      "| [15.0,1.0,1.0]|            3|[13.0,77.0,113.0,...|[0.03746397694524...|       2.0|\n",
      "| [15.0,1.0,1.0]|            3|[13.0,77.0,113.0,...|[0.03746397694524...|       2.0|\n",
      "| [15.0,1.0,2.0]|            4|[13.0,77.0,113.0,...|[0.03746397694524...|       2.0|\n",
      "| [15.0,4.0,1.0]|            4|[0.0,3.0,3.0,8.0,...|[0.0,0.1764705882...|       3.0|\n",
      "|[15.0,42.0,1.0]|            4|[8.0,39.0,50.0,29...|[0.04878048780487...|       2.0|\n",
      "|[16.0,17.0,1.0]|            4|[8.0,39.0,50.0,29...|[0.04878048780487...|       2.0|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            3|       2.0|\n",
      "|            3|       2.0|\n",
      "|            2|       2.0|\n",
      "|            4|       3.0|\n",
      "|            4|       2.0|\n",
      "|            4|       3.0|\n",
      "|            1|       0.0|\n",
      "|            4|       2.0|\n",
      "|            4|       2.0|\n",
      "|            3|       2.0|\n",
      "|            3|       2.0|\n",
      "|            4|       2.0|\n",
      "|            1|       2.0|\n",
      "|            1|       2.0|\n",
      "|            3|       2.0|\n",
      "|            3|       2.0|\n",
      "|            4|       2.0|\n",
      "|            4|       3.0|\n",
      "|            4|       2.0|\n",
      "|            4|       2.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3457478890229192"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "# Split the data into training and validation data\n",
    "train_data, validation_data = finalized_data.randomSplit([0.1, 0.9])\n",
    "classifier = DecisionTreeClassifier( labelCol='AdoptionSpeed', featuresCol='features')\n",
    "classifier = classifier.fit(train_data) # Fit the model\n",
    "results = classifier.transform(validation_data) # Evaluate the model on the validation data\n",
    "results.show() # Show the predictions\n",
    "results.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "# results.accuracy # Show the accuracy of the model\n",
    "results.accuracy = results.filter(results.AdoptionSpeed == results.prediction).count() / float(results.count())\n",
    "results.accuracy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|       features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|  [0.0,2.0,1.0]|            3|[0.57093352581894...|[0.02854667629094...|       3.0|\n",
      "|  [0.0,3.0,2.0]|            2|[3.02215758377512...|[0.15110787918875...|       4.0|\n",
      "|  [0.0,4.0,1.0]|            4|[1.20749549953330...|[0.06037477497666...|       3.0|\n",
      "| [0.0,72.0,1.0]|            4|[0.91732063664329...|[0.04586603183216...|       4.0|\n",
      "|  [5.0,0.0,1.0]|            1|[0.62544942282832...|[0.03127247114141...|       3.0|\n",
      "| [7.0,14.0,1.0]|            4|[1.34838616332124...|[0.06741930816606...|       2.0|\n",
      "|[10.0,60.0,1.0]|            3|[0.91732063664329...|[0.04586603183216...|       4.0|\n",
      "|[10.0,84.0,1.0]|            3|[0.91732063664329...|[0.04586603183216...|       4.0|\n",
      "| [11.0,1.0,1.0]|            4|[0.30044942282832...|[0.01502247114141...|       3.0|\n",
      "| [15.0,1.0,1.0]|            1|[0.30044942282832...|[0.01502247114141...|       3.0|\n",
      "| [15.0,1.0,1.0]|            1|[0.30044942282832...|[0.01502247114141...|       3.0|\n",
      "| [15.0,1.0,1.0]|            3|[0.30044942282832...|[0.01502247114141...|       3.0|\n",
      "| [15.0,1.0,1.0]|            3|[0.30044942282832...|[0.01502247114141...|       3.0|\n",
      "| [15.0,1.0,2.0]|            4|[0.76875356556009...|[0.03843767827800...|       4.0|\n",
      "| [15.0,4.0,1.0]|            4|[1.20749549953330...|[0.06037477497666...|       3.0|\n",
      "|[15.0,42.0,1.0]|            4|[0.96107063664329...|[0.04805353183216...|       4.0|\n",
      "|[16.0,17.0,1.0]|            4|[1.34838616332124...|[0.06741930816606...|       2.0|\n",
      "| [17.0,5.0,1.0]|            1|[0.61667402740377...|[0.03083370137018...|       1.0|\n",
      "|[17.0,36.0,1.0]|            3|[0.90744434741793...|[0.04537221737089...|       4.0|\n",
      "|[17.0,38.0,1.0]|            4|[0.96107063664329...|[0.04805353183216...|       4.0|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            3|       3.0|\n",
      "|            2|       4.0|\n",
      "|            4|       3.0|\n",
      "|            4|       4.0|\n",
      "|            1|       3.0|\n",
      "|            4|       2.0|\n",
      "|            3|       4.0|\n",
      "|            3|       4.0|\n",
      "|            4|       3.0|\n",
      "|            1|       3.0|\n",
      "|            1|       3.0|\n",
      "|            3|       3.0|\n",
      "|            3|       3.0|\n",
      "|            4|       4.0|\n",
      "|            4|       3.0|\n",
      "|            4|       4.0|\n",
      "|            4|       2.0|\n",
      "|            1|       1.0|\n",
      "|            3|       4.0|\n",
      "|            4|       4.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34957818620066283"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "# Split the data into training and validation data\n",
    "train_data, validation_data = finalized_data.randomSplit([0.1, 0.9])\n",
    "classifier = RandomForestClassifier( labelCol='AdoptionSpeed', featuresCol='features')\n",
    "classifier = classifier.fit(train_data) # Fit the model\n",
    "results = classifier.transform(validation_data) # Evaluate the model on the validation data\n",
    "results.show() # Show the predictions\n",
    "results.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "# results.accuracy # Show the accuracy of the model\n",
    "results.accuracy = results.filter(results.AdoptionSpeed == results.prediction).count() / float(results.count())\n",
    "results.accuracy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|       features|AdoptionSpeed|       rawPrediction|         probability|prediction|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "|  [0.0,2.0,1.0]|            3|[-14.872410311282...|[0.04281955876827...|       4.0|\n",
      "|  [0.0,2.0,1.0]|            3|[-14.872410311282...|[0.04281955876827...|       4.0|\n",
      "|  [0.0,3.0,2.0]|            2|[-23.187144547845...|[0.05007950646776...|       4.0|\n",
      "|  [0.0,4.0,1.0]|            4|[-21.278048371913...|[0.04236192109208...|       4.0|\n",
      "| [0.0,72.0,1.0]|            4|[-239.06974243336...|[6.22502274660779...|       4.0|\n",
      "|  [1.0,5.0,1.0]|            4|[-24.528663649522...|[0.04115440869555...|       4.0|\n",
      "|  [5.0,0.0,1.0]|            1|[-8.7057534871198...|[0.03938349811024...|       2.0|\n",
      "| [7.0,14.0,1.0]|            4|[-53.640812406122...|[0.02204981536654...|       4.0|\n",
      "|[10.0,60.0,1.0]|            3|[-201.11387654251...|[2.25944226879971...|       4.0|\n",
      "|[10.0,84.0,1.0]|            3|[-277.98153327008...|[1.82255340084911...|       4.0|\n",
      "| [11.0,1.0,1.0]|            4|[-12.195350001197...|[0.04091554345207...|       4.0|\n",
      "| [15.0,1.0,1.0]|            1|[-12.386534990372...|[0.04055445346831...|       4.0|\n",
      "| [15.0,1.0,1.0]|            1|[-12.386534990372...|[0.04055445346831...|       4.0|\n",
      "| [15.0,1.0,1.0]|            3|[-12.386534990372...|[0.04055445346831...|       4.0|\n",
      "| [15.0,1.0,1.0]|            3|[-12.386534990372...|[0.04055445346831...|       4.0|\n",
      "| [15.0,1.0,2.0]|            4|[-17.498450196620...|[0.04634979468944...|       2.0|\n",
      "| [15.0,4.0,1.0]|            4|[-21.994992081318...|[0.04248651289887...|       4.0|\n",
      "|[15.0,42.0,1.0]|            4|[-143.70211523330...|[0.00146190922770...|       4.0|\n",
      "|[16.0,17.0,1.0]|            4|[-63.679435722712...|[0.01723335096543...|       4.0|\n",
      "| [17.0,5.0,1.0]|            1|[-25.293403606221...|[0.04164565072369...|       4.0|\n",
      "+---------------+-------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------------+----------+\n",
      "|AdoptionSpeed|prediction|\n",
      "+-------------+----------+\n",
      "|            3|       4.0|\n",
      "|            3|       4.0|\n",
      "|            2|       4.0|\n",
      "|            4|       4.0|\n",
      "|            4|       4.0|\n",
      "|            4|       4.0|\n",
      "|            1|       2.0|\n",
      "|            4|       4.0|\n",
      "|            3|       4.0|\n",
      "|            3|       4.0|\n",
      "|            4|       4.0|\n",
      "|            1|       4.0|\n",
      "|            1|       4.0|\n",
      "|            3|       4.0|\n",
      "|            3|       4.0|\n",
      "|            4|       2.0|\n",
      "|            4|       4.0|\n",
      "|            4|       4.0|\n",
      "|            4|       4.0|\n",
      "|            1|       4.0|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2663183401484174"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "# Split the data into training and validation data\n",
    "train_data, validation_data = finalized_data.randomSplit([0.1, 0.9])\n",
    "classifier = NaiveBayes( labelCol='AdoptionSpeed', featuresCol='features')\n",
    "classifier = classifier.fit(train_data) # Fit the model\n",
    "results = classifier.transform(validation_data) # Evaluate the model on the validation data\n",
    "results.show() # Show the predictions\n",
    "results.select('AdoptionSpeed', 'prediction').show() # Show the target and the prediction\n",
    "# results.accuracy # Show the accuracy of the model\n",
    "results.accuracy = results.filter(results.AdoptionSpeed == results.prediction).count() / float(results.count())\n",
    "results.accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
